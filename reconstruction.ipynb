{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reconstruction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc51zuDjrkyB"
      },
      "source": [
        "!unzip /content/test1.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54hzlP05qzRX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0bba2b32-744a-49c6-b715-d1ef718a8ba6"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "from keras.models import Model\n",
        "from keras import losses\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
        "from keras.layers import MaxPooling2D, Dropout, UpSampling2D"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFNdaU31Ih8q"
      },
      "source": [
        "import random\n",
        "import sys\n",
        "import dlib\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_lacQ10q9pe"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXvLfgfH9inu"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KGcVP_orAFX"
      },
      "source": [
        "TRAIN_IMAGES = glob.glob('/content/drive/My Drive/colab_data/cat_data/train_cat/*.jpg')\n",
        "CLEAN_IMAGES = glob.glob('/content/drive/My Drive/colab_data/cat_data/train_cat/*.jpg')\n",
        "TEST_IMAGES = glob.glob('/content/drive/My Drive/colab_data/test_images/*.jpeg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3En8XpNcIkPR"
      },
      "source": [
        "####################landmarks#########################################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNa5AvqxF_Fq"
      },
      "source": [
        "df=pd.read_csv(\"/content/sample_data/california_housing_train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvvOnpWkIIar"
      },
      "source": [
        "train_lmks= {'tr_lmks': []}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZ9hBOJ0UqgT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONQgsMXgIIk_"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/colab_data') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1y_DgXCIa_B"
      },
      "source": [
        "  base_path = os.getcwd() + \"/\" \n",
        "  file_list = sorted(os.listdir(base_path))\n",
        "  random.shuffle(file_list)\n",
        "  pd_frame = pd.read_csv(os.path.join(base_path, 'training_human_32x32.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txZRwR8hIIxf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "de3ef0e6-acfe-43dd-ff43-e59d0056d8d5"
      },
      "source": [
        "for i in range(0, 1713):\n",
        "  \n",
        "  landmark = (pd_frame.as_matrix()[i][0:6]).reshape((-1, 2))\n",
        "  train_lmks['tr_lmks'].append(landmark.flatten())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwQAWDuRJnwu"
      },
      "source": [
        "np.save('/content/drive/My Drive/colab_data/' + 'tr_lmks.npy', np.array(train_lmks))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-tDGsw7II8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3adae6cc-b812-4f7f-9cb9-27640bd95db1"
      },
      "source": [
        "data_00 = np.load('/content/drive/My Drive/colab_data/tr_lmks.npy',allow_pickle=True)\n",
        "hy_train = np.array(data_00.item().get('tr_lmks'))\n",
        "hy_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1713, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhTiUeLPKjcQ"
      },
      "source": [
        "##########################################################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHZAT9SsrD-v"
      },
      "source": [
        "def load_image(path):\n",
        "    image_list = np.zeros((len(path),32,32, 3))\n",
        "    for i, fig in enumerate(path):\n",
        "        img = image.load_img(fig, color_mode='rgb', target_size=(32,32))\n",
        "        x = image.img_to_array(img).astype('float32')\n",
        "        x = x / 255.0\n",
        "        image_list[i] = x\n",
        "    \n",
        "    return image_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tbhLeM3rG2W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b63b7058-c2e1-481e-e3f3-390b6df59dd3"
      },
      "source": [
        "\n",
        "x_train = load_image(TRAIN_IMAGES)\n",
        "y_train = load_image(CLEAN_IMAGES)\n",
        "x_test = load_image(TEST_IMAGES)\n",
        "\n",
        "print(x_train.shape, x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(770, 32, 32, 3) (1713, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htDzxcH7rH3-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47740c36-5b67-4dc5-b671-e6e40de1ca25"
      },
      "source": [
        "def train_val_split(x_train, y_train):\n",
        "    rnd = np.random.RandomState(seed=42)\n",
        "    perm = rnd.permutation(len(x_train))\n",
        "    train_idx = perm[:int(0.8 * len(x_train))]\n",
        "    val_idx = perm[int(0.8 * len(x_train)):]\n",
        "    return x_train[train_idx], y_train[train_idx], x_train[val_idx], y_train[val_idx]\n",
        "\n",
        "x_train, y_train, x_val, y_val = train_val_split(x_train, y_train)\n",
        "print(x_train.shape, x_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(616, 32, 32, 3) (154, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIpJQY2iue0y"
      },
      "source": [
        "data_01 = np.load('/content/drive/My Drive/colab_data/tr_new.npy',allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE2c5HCQu-RL"
      },
      "source": [
        "img_size=32\n",
        "output_size=6\n",
        "hx_train = np.array(data_00.item().get('tr_imgs'))\n",
        "hy_train = np.array(data_00.item().get('tr_lmks'))\n",
        "hx_train = x_train.astype('float32') / 255.\n",
        "hx_train = np.reshape(x_train, (-1, img_size, img_size, 1))\n",
        "hy_train = np.reshape(y_train, (-1, output_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxJqkM7MrOBG"
      },
      "source": [
        "class Autoencoder():\n",
        "    def __init__(self):\n",
        "        self.img_rows = 32\n",
        "        self.img_cols = 32\n",
        "        self.channels = 3\n",
        "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
        "        \n",
        "        optimizer = Adam(lr=0.0003)\n",
        "        \n",
        "        self.autoencoder_model, self.subModel = self.build_model() \n",
        "        self.reg=self.reg_model()\n",
        "        self.autoencoder_model.compile(loss='mse', optimizer=optimizer)\n",
        "        self.autoencoder_model.summary()\n",
        "    \n",
        "    def build_model(self):\n",
        "        input_layer = Input(shape=self.img_shape)\n",
        "        \n",
        "        # encoder\n",
        "        h = Conv2D(300, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "        h = MaxPooling2D((2, 2), padding='same')(h)\n",
        "        h = Conv2D(250,(3,3),activation='relu',padding='same')(h)\n",
        "        h=MaxPooling2D((2,2),padding='same')(h)\n",
        "        h=Conv2D(200,(3,3),activation='relu',padding='same')(h)\n",
        "        h=Conv2D(150,(3,3),activation='relu',padding='same')(h)\n",
        "        h=Conv2D(100,(3,3),activation='relu',padding='same')(h)\n",
        "        h=Dense(500, activation='relu', name='submodel')(h)\n",
        "        encoder = Model(input_layer,h)\n",
        "        # decoder\n",
        "        h=Dense(500)(h)\n",
        "        h = Conv2D(100, (3, 3), activation='relu', padding='same')(h)\n",
        "        h=Conv2D(150,(3,3),activation='relu',padding='same')(h)\n",
        "        h=Conv2D(200,(3,3),activation='relu',padding='same')(h)\n",
        "        h =Conv2D(250,(3,3),activation='relu',padding='same')(h)\n",
        "        h = UpSampling2D((2, 2))(h)\n",
        "        h = Conv2D(300, (3, 3), activation='relu', padding='same')(h)\n",
        "        h = UpSampling2D((2, 2))(h)\n",
        "        output_layer = Conv2D(3, (3, 3), activation='tanh', padding='same')(h)\n",
        "        \n",
        "        model = Model(input_layer, output_layer)\n",
        "        \n",
        "        subModel = Model(model.input, model.get_layer('submodel').output)\n",
        "        \n",
        "        return model, subModel\n",
        "    \n",
        "    def reg_model(self):\n",
        "      input_layer= Input(shape=(8,8,500))\n",
        "      h= Flatten()(input_layer)\n",
        "      regression_layer= Dense(6, activation='linear')(h)\n",
        "      reg= Model(input_layer, regression_layer)\n",
        "      reg.summary()\n",
        "      return reg\n",
        "    \n",
        "    def human_train(self, hx_train, hy_train, epochs, batch_size=128):\n",
        "      optimizer = Adam(lr=0.0003)\n",
        "      self.reg.compile(optimizer, loss=losses.mean_squared_error,metrics=[\"accuracy\"])\n",
        "      self.reg.fit(hx_train, hy_train, epochs=20, batch_size=batch_size, shuffle=True, verbose=1)\n",
        "      self.reg.save('reg_model.h5')\n",
        "      \n",
        "      \n",
        "      \n",
        "      \n",
        "    \n",
        "    def train_model(self, x_train, y_train, x_val, y_val, epochs, batch_size=128):\n",
        "        optimizer = Adam(lr=0.0003)\n",
        "        self.autoencoder_model.compile(optimizer,loss=losses.mean_squared_error,metrics=[\"accuracy\"])\n",
        "        self.autoencoder_model.fit(x_train, y_train,\n",
        "                                             batch_size=batch_size,\n",
        "                                             epochs=100,\n",
        "                                             verbose=1,\n",
        "                                             validation_data=(x_val, y_val))\n",
        "  \n",
        "        self.autoencoder_model.save('ae2.h5')\n",
        "        self.subModel.save('sub2.h5')\n",
        "      \n",
        "    def eval_reg(self, x1_test):\n",
        "        pred_reg=self.reg.predict(x1_test)\n",
        "        return pred_reg\n",
        "\n",
        "       \n",
        "    def eval_model(self, x_test):\n",
        "        preds = self.autoencoder_model.predict(x_test)\n",
        "        predictions = self.subModel.predict(x_test)\n",
        "        return preds, predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AWVY8iXrU1O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4709
        },
        "outputId": "681985af-35cf-4dcf-c56a-dfcf04609434"
      },
      "source": [
        "ae = Autoencoder()\n",
        "ae.train_model(x_train, y_train, x_val, y_val, epochs=100, batch_size=128)\n",
        "\n",
        "ae.human_train(predictions, hy_train, epochs=100, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        (None, 8, 8, 500)         0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 32000)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 6)                 192006    \n",
            "=================================================================\n",
            "Total params: 192,006\n",
            "Trainable params: 192,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_9 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 32, 32, 300)       8400      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 300)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 16, 16, 250)       675250    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 8, 8, 250)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 8, 8, 200)         450200    \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 8, 8, 150)         270150    \n",
            "_________________________________________________________________\n",
            "conv2d_49 (Conv2D)           (None, 8, 8, 100)         135100    \n",
            "_________________________________________________________________\n",
            "submodel (Dense)             (None, 8, 8, 500)         50500     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 8, 8, 500)         250500    \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 8, 8, 100)         450100    \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 8, 8, 150)         135150    \n",
            "_________________________________________________________________\n",
            "conv2d_52 (Conv2D)           (None, 8, 8, 200)         270200    \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           (None, 8, 8, 250)         450250    \n",
            "_________________________________________________________________\n",
            "up_sampling2d_9 (UpSampling2 (None, 16, 16, 250)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_54 (Conv2D)           (None, 16, 16, 300)       675300    \n",
            "_________________________________________________________________\n",
            "up_sampling2d_10 (UpSampling (None, 32, 32, 300)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 32, 32, 3)         8103      \n",
            "=================================================================\n",
            "Total params: 3,829,203\n",
            "Trainable params: 3,829,203\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 616 samples, validate on 154 samples\n",
            "Epoch 1/100\n",
            "616/616 [==============================] - 3s 4ms/step - loss: 0.1962 - acc: 0.1852 - val_loss: 0.0677 - val_acc: 0.7682\n",
            "Epoch 2/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0738 - acc: 0.7733 - val_loss: 0.0831 - val_acc: 0.8020\n",
            "Epoch 3/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0612 - acc: 0.7816 - val_loss: 0.0456 - val_acc: 0.7796\n",
            "Epoch 4/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0453 - acc: 0.7542 - val_loss: 0.0454 - val_acc: 0.8060\n",
            "Epoch 5/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0414 - acc: 0.7868 - val_loss: 0.0401 - val_acc: 0.8086\n",
            "Epoch 6/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0372 - acc: 0.7881 - val_loss: 0.0367 - val_acc: 0.8088\n",
            "Epoch 7/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0343 - acc: 0.7885 - val_loss: 0.0341 - val_acc: 0.8095\n",
            "Epoch 8/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0321 - acc: 0.7895 - val_loss: 0.0323 - val_acc: 0.8101\n",
            "Epoch 9/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0298 - acc: 0.7897 - val_loss: 0.0301 - val_acc: 0.8087\n",
            "Epoch 10/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0274 - acc: 0.7894 - val_loss: 0.0269 - val_acc: 0.8100\n",
            "Epoch 11/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0249 - acc: 0.7896 - val_loss: 0.0246 - val_acc: 0.8093\n",
            "Epoch 12/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0228 - acc: 0.7893 - val_loss: 0.0231 - val_acc: 0.8093\n",
            "Epoch 13/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0222 - acc: 0.7896 - val_loss: 0.0235 - val_acc: 0.8101\n",
            "Epoch 14/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0212 - acc: 0.7896 - val_loss: 0.0209 - val_acc: 0.8100\n",
            "Epoch 15/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0199 - acc: 0.7896 - val_loss: 0.0196 - val_acc: 0.8101\n",
            "Epoch 16/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0190 - acc: 0.7897 - val_loss: 0.0189 - val_acc: 0.8101\n",
            "Epoch 17/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0185 - acc: 0.7895 - val_loss: 0.0195 - val_acc: 0.8101\n",
            "Epoch 18/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0182 - acc: 0.7896 - val_loss: 0.0183 - val_acc: 0.8100\n",
            "Epoch 19/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0175 - acc: 0.7894 - val_loss: 0.0175 - val_acc: 0.8092\n",
            "Epoch 20/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0171 - acc: 0.7891 - val_loss: 0.0172 - val_acc: 0.8079\n",
            "Epoch 21/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0166 - acc: 0.7874 - val_loss: 0.0176 - val_acc: 0.8051\n",
            "Epoch 22/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0165 - acc: 0.7882 - val_loss: 0.0167 - val_acc: 0.8003\n",
            "Epoch 23/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0164 - acc: 0.7852 - val_loss: 0.0167 - val_acc: 0.8060\n",
            "Epoch 24/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0160 - acc: 0.7876 - val_loss: 0.0170 - val_acc: 0.8016\n",
            "Epoch 25/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0160 - acc: 0.7854 - val_loss: 0.0159 - val_acc: 0.8042\n",
            "Epoch 26/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0153 - acc: 0.7838 - val_loss: 0.0161 - val_acc: 0.7933\n",
            "Epoch 27/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0151 - acc: 0.7825 - val_loss: 0.0152 - val_acc: 0.7994\n",
            "Epoch 28/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0147 - acc: 0.7825 - val_loss: 0.0152 - val_acc: 0.7918\n",
            "Epoch 29/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0145 - acc: 0.7816 - val_loss: 0.0147 - val_acc: 0.7966\n",
            "Epoch 30/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0142 - acc: 0.7783 - val_loss: 0.0152 - val_acc: 0.7983\n",
            "Epoch 31/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0141 - acc: 0.7820 - val_loss: 0.0151 - val_acc: 0.7921\n",
            "Epoch 32/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0140 - acc: 0.7801 - val_loss: 0.0147 - val_acc: 0.7951\n",
            "Epoch 33/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0137 - acc: 0.7786 - val_loss: 0.0149 - val_acc: 0.7873\n",
            "Epoch 34/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0136 - acc: 0.7757 - val_loss: 0.0143 - val_acc: 0.7644\n",
            "Epoch 35/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0133 - acc: 0.7588 - val_loss: 0.0136 - val_acc: 0.8014\n",
            "Epoch 36/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0132 - acc: 0.7620 - val_loss: 0.0130 - val_acc: 0.7698\n",
            "Epoch 37/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0125 - acc: 0.7660 - val_loss: 0.0126 - val_acc: 0.8084\n",
            "Epoch 38/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0120 - acc: 0.7684 - val_loss: 0.0124 - val_acc: 0.8071\n",
            "Epoch 39/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0119 - acc: 0.7802 - val_loss: 0.0174 - val_acc: 0.7012\n",
            "Epoch 40/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0196 - acc: 0.7618 - val_loss: 0.0158 - val_acc: 0.6478\n",
            "Epoch 41/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0168 - acc: 0.7515 - val_loss: 0.0170 - val_acc: 0.8033\n",
            "Epoch 42/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0153 - acc: 0.7495 - val_loss: 0.0136 - val_acc: 0.8074\n",
            "Epoch 43/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0140 - acc: 0.7851 - val_loss: 0.0150 - val_acc: 0.7471\n",
            "Epoch 44/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0131 - acc: 0.7670 - val_loss: 0.0125 - val_acc: 0.7857\n",
            "Epoch 45/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0122 - acc: 0.7690 - val_loss: 0.0126 - val_acc: 0.8017\n",
            "Epoch 46/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0117 - acc: 0.7691 - val_loss: 0.0119 - val_acc: 0.8026\n",
            "Epoch 47/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0114 - acc: 0.7897 - val_loss: 0.0118 - val_acc: 0.7928\n",
            "Epoch 48/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0112 - acc: 0.7818 - val_loss: 0.0117 - val_acc: 0.7919\n",
            "Epoch 49/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0110 - acc: 0.7927 - val_loss: 0.0116 - val_acc: 0.7815\n",
            "Epoch 50/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0108 - acc: 0.7987 - val_loss: 0.0113 - val_acc: 0.7905\n",
            "Epoch 51/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0107 - acc: 0.7987 - val_loss: 0.0111 - val_acc: 0.8047\n",
            "Epoch 52/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0105 - acc: 0.8068 - val_loss: 0.0110 - val_acc: 0.7920\n",
            "Epoch 53/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0104 - acc: 0.8044 - val_loss: 0.0109 - val_acc: 0.7987\n",
            "Epoch 54/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0103 - acc: 0.8062 - val_loss: 0.0108 - val_acc: 0.7895\n",
            "Epoch 55/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0102 - acc: 0.8066 - val_loss: 0.0108 - val_acc: 0.7992\n",
            "Epoch 56/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0102 - acc: 0.8100 - val_loss: 0.0106 - val_acc: 0.7971\n",
            "Epoch 57/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0102 - acc: 0.7993 - val_loss: 0.0108 - val_acc: 0.8159\n",
            "Epoch 58/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0102 - acc: 0.7869 - val_loss: 0.0106 - val_acc: 0.8113\n",
            "Epoch 59/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0100 - acc: 0.8063 - val_loss: 0.0106 - val_acc: 0.7650\n",
            "Epoch 60/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0100 - acc: 0.7943 - val_loss: 0.0108 - val_acc: 0.8141\n",
            "Epoch 61/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0103 - acc: 0.8110 - val_loss: 0.0105 - val_acc: 0.7761\n",
            "Epoch 62/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0100 - acc: 0.8021 - val_loss: 0.0105 - val_acc: 0.8149\n",
            "Epoch 63/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0098 - acc: 0.8122 - val_loss: 0.0104 - val_acc: 0.7672\n",
            "Epoch 64/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0097 - acc: 0.8073 - val_loss: 0.0102 - val_acc: 0.8105\n",
            "Epoch 65/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0096 - acc: 0.8128 - val_loss: 0.0101 - val_acc: 0.8132\n",
            "Epoch 66/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0095 - acc: 0.8116 - val_loss: 0.0102 - val_acc: 0.7842\n",
            "Epoch 67/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0099 - acc: 0.8059 - val_loss: 0.0109 - val_acc: 0.7563\n",
            "Epoch 68/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0098 - acc: 0.7991 - val_loss: 0.0103 - val_acc: 0.8156\n",
            "Epoch 69/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0096 - acc: 0.7926 - val_loss: 0.0101 - val_acc: 0.7675\n",
            "Epoch 70/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0094 - acc: 0.8018 - val_loss: 0.0101 - val_acc: 0.8190\n",
            "Epoch 71/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0093 - acc: 0.8075 - val_loss: 0.0100 - val_acc: 0.7442\n",
            "Epoch 72/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0092 - acc: 0.7972 - val_loss: 0.0098 - val_acc: 0.8130\n",
            "Epoch 73/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0098 - acc: 0.8109 - val_loss: 0.0121 - val_acc: 0.7688\n",
            "Epoch 74/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0101 - acc: 0.7864 - val_loss: 0.0102 - val_acc: 0.8133\n",
            "Epoch 75/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0094 - acc: 0.7978 - val_loss: 0.0098 - val_acc: 0.8153\n",
            "Epoch 76/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0092 - acc: 0.8083 - val_loss: 0.0100 - val_acc: 0.7862\n",
            "Epoch 77/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0092 - acc: 0.8129 - val_loss: 0.0096 - val_acc: 0.8060\n",
            "Epoch 78/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0090 - acc: 0.8159 - val_loss: 0.0094 - val_acc: 0.8091\n",
            "Epoch 79/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0088 - acc: 0.8206 - val_loss: 0.0094 - val_acc: 0.7898\n",
            "Epoch 80/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0087 - acc: 0.8148 - val_loss: 0.0094 - val_acc: 0.8075\n",
            "Epoch 81/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0088 - acc: 0.8143 - val_loss: 0.0092 - val_acc: 0.8222\n",
            "Epoch 82/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0086 - acc: 0.8121 - val_loss: 0.0093 - val_acc: 0.7947\n",
            "Epoch 83/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0094 - acc: 0.8219 - val_loss: 0.0109 - val_acc: 0.8087\n",
            "Epoch 84/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0093 - acc: 0.8000 - val_loss: 0.0094 - val_acc: 0.8166\n",
            "Epoch 85/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0091 - acc: 0.7998 - val_loss: 0.0094 - val_acc: 0.8183\n",
            "Epoch 86/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0087 - acc: 0.8051 - val_loss: 0.0093 - val_acc: 0.7521\n",
            "Epoch 87/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0085 - acc: 0.8033 - val_loss: 0.0092 - val_acc: 0.8176\n",
            "Epoch 88/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0084 - acc: 0.8130 - val_loss: 0.0090 - val_acc: 0.8019\n",
            "Epoch 89/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0084 - acc: 0.8130 - val_loss: 0.0091 - val_acc: 0.8176\n",
            "Epoch 90/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0083 - acc: 0.8221 - val_loss: 0.0091 - val_acc: 0.7984\n",
            "Epoch 91/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0084 - acc: 0.8132 - val_loss: 0.0088 - val_acc: 0.8218\n",
            "Epoch 92/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0081 - acc: 0.8204 - val_loss: 0.0086 - val_acc: 0.8016\n",
            "Epoch 93/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0080 - acc: 0.8201 - val_loss: 0.0086 - val_acc: 0.7928\n",
            "Epoch 94/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0080 - acc: 0.8164 - val_loss: 0.0086 - val_acc: 0.8254\n",
            "Epoch 95/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0080 - acc: 0.8167 - val_loss: 0.0092 - val_acc: 0.8201\n",
            "Epoch 96/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0109 - acc: 0.8250 - val_loss: 0.0090 - val_acc: 0.7539\n",
            "Epoch 97/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0094 - acc: 0.7920 - val_loss: 0.0099 - val_acc: 0.8157\n",
            "Epoch 98/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0087 - acc: 0.8096 - val_loss: 0.0090 - val_acc: 0.8251\n",
            "Epoch 99/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0083 - acc: 0.8047 - val_loss: 0.0089 - val_acc: 0.7495\n",
            "Epoch 100/100\n",
            "616/616 [==============================] - 1s 2ms/step - loss: 0.0082 - acc: 0.7997 - val_loss: 0.0087 - val_acc: 0.8157\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-cd6e76a4ee11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhuman_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-48-2a1239a0db59>\u001b[0m in \u001b[0;36mhuman_train\u001b[0;34m(self, hx_train, hy_train, epochs, batch_size)\u001b[0m\n\u001b[1;32m     54\u001b[0m       \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0003\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reg_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    802\u001b[0m             ]\n\u001b[1;32m    803\u001b[0m             \u001b[0;31m# Check that all arrays have the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 804\u001b[0;31m             \u001b[0mcheck_array_length_consistency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m                 \u001b[0;31m# Additional checks to avoid users mistakenly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_array_length_consistency\u001b[0;34m(inputs, targets, weights)\u001b[0m\n\u001b[1;32m    235\u001b[0m                          \u001b[0;34m'the same number of samples as target arrays. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                          \u001b[0;34m'Found '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' input samples '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                          'and ' + str(list(set_y)[0]) + ' target samples.')\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         raise ValueError('All sample_weight arrays should have '\n",
            "\u001b[0;31mValueError\u001b[0m: Input arrays should have the same number of samples as target arrays. Found 1713 input samples and 315392 target samples."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5z_n-GLcAWX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jyF36CHFT70"
      },
      "source": [
        "model=load_model(\"ae1.h5\")\n",
        "model.compile(optimizer=\"adam\",loss=losses.mean_squared_error,metrics=[\"accuracy\"])\n",
        "# model.fit(x_train, y_train,batch_size=128,epochs=50,validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH4f45nkrVh1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae9c2614-3d4c-469b-eec9-46a89be4cef3"
      },
      "source": [
        "preds, predictions = ae.eval_model(x_test)\n",
        "pred_reg = ae.eval_reg(predictions)\n",
        "pred_reg.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1713, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDKC6OXVi6rb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0f070ac-bb14-4cb4-b081-da73494b461b"
      },
      "source": [
        "predictions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1713, 8, 8, 500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfeNzni1F8AM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOkwcy33rZZM"
      },
      "source": [
        "preds_0 = preds[9].reshape(32,32,3)\n",
        "x_test_0 = x_test[9] * 255.0\n",
        "x_test_0 = x_test_0.reshape(32,32,3)\n",
        "plt.imshow(x_test_0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xjv5H_2jrbzr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "9c1490eb-6b16-4fd3-a693-72fcb366bf99"
      },
      "source": [
        "plt.imshow(preds_0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f39c70d1c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCzVO9uKEmSYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}